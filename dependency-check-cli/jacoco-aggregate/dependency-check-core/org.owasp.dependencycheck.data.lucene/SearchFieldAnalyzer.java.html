<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../jacoco-resources/report.gif" type="image/gif"/><title>SearchFieldAnalyzer.java</title><link rel="stylesheet" href="../../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../../index.html" class="el_report">Dependency-Check Command Line</a> &gt; <a href="../index.html" class="el_bundle">dependency-check-core</a> &gt; <a href="index.source.html" class="el_package">org.owasp.dependencycheck.data.lucene</a> &gt; <span class="el_source">SearchFieldAnalyzer.java</span></div><h1>SearchFieldAnalyzer.java</h1><pre class="source lang-java linenums">/*
 * This file is part of dependency-check-core.
 *
 * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 * Copyright (c) 2012 Jeremy Long. All Rights Reserved.
 */
package org.owasp.dependencycheck.data.lucene;

import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.analysis.TokenStream;
import org.apache.lucene.analysis.Tokenizer;
import org.apache.lucene.analysis.core.LowerCaseFilter;
import org.apache.lucene.analysis.core.StopAnalyzer;
import org.apache.lucene.analysis.core.StopFilter;
import org.apache.lucene.analysis.core.WhitespaceTokenizer;
import org.apache.lucene.analysis.miscellaneous.WordDelimiterFilter;
import org.apache.lucene.analysis.util.CharArraySet;

/**
 * A Lucene field analyzer used to analyzer queries against the CPE data.
 *
 * @author Jeremy Long
 */
public class SearchFieldAnalyzer extends Analyzer {

    /**
     * The list of additional stop words to use.
     */
<span class="fc" id="L40">    private static final String[] ADDITIONAL_STOP_WORDS = {&quot;software&quot;, &quot;framework&quot;, &quot;inc&quot;,</span>
        &quot;com&quot;, &quot;org&quot;, &quot;net&quot;, &quot;www&quot;, &quot;consulting&quot;, &quot;ltd&quot;, &quot;foundation&quot;, &quot;project&quot;};
    /**
     * The set of stop words to use in the analyzer.
     */
    private final CharArraySet stopWords;

    /**
     * Returns the set of stop words being used.
     *
     * @return the set of stop words being used
     */
    public static CharArraySet getStopWords() {
<span class="fc" id="L53">        final CharArraySet words = StopFilter.makeStopSet(ADDITIONAL_STOP_WORDS, true);</span>
<span class="fc" id="L54">        words.addAll(StopAnalyzer.ENGLISH_STOP_WORDS_SET);</span>
<span class="fc" id="L55">        return words;</span>
    }

    /**
     * Constructs a new SearchFieldAnalyzer.
     *
     */
<span class="fc" id="L62">    public SearchFieldAnalyzer() {</span>
<span class="fc" id="L63">        stopWords = getStopWords();</span>
<span class="fc" id="L64">    }</span>

    /**
     * Creates a the TokenStreamComponents used to analyze the stream.
     *
     * @param fieldName the field that this lucene analyzer will process
     * @return the token stream filter chain
     */
    @Override
    protected TokenStreamComponents createComponents(String fieldName) {
        //final Tokenizer source = new AlphaNumericTokenizer();
<span class="fc" id="L75">        final Tokenizer source = new WhitespaceTokenizer();</span>
<span class="fc" id="L76">        TokenStream stream = source;</span>

<span class="fc" id="L78">        stream = new UrlTokenizingFilter(stream);</span>
<span class="fc" id="L79">        stream = new AlphaNumericFilter(stream);</span>
<span class="fc" id="L80">        stream = new WordDelimiterFilter(stream,</span>
                WordDelimiterFilter.GENERATE_WORD_PARTS
                | WordDelimiterFilter.GENERATE_NUMBER_PARTS
                | WordDelimiterFilter.PRESERVE_ORIGINAL
                | WordDelimiterFilter.SPLIT_ON_CASE_CHANGE
                | WordDelimiterFilter.SPLIT_ON_NUMERICS
                | WordDelimiterFilter.STEM_ENGLISH_POSSESSIVE, null);

<span class="fc" id="L88">        stream = new LowerCaseFilter(stream);</span>

<span class="fc" id="L90">        stream = new StopFilter(stream, stopWords);</span>
<span class="fc" id="L91">        stream = new TokenPairConcatenatingFilter(stream);</span>

<span class="fc" id="L93">        return new TokenStreamComponents(source, stream);</span>
    }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.7.9.201702052155</span></div></body></html>